{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import urllib.request\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_request_url(url):\n",
    "    \n",
    "    req = urllib.request.Request(url)\n",
    "    req.add_header(\"X-Naver-Client-Id\", \"jL0_Mj8EcTrEmAvqNflt\")\n",
    "    req.add_header(\"X-Naver-Client-Secret\", \"XjFsAbKpCH\")\n",
    "    try: \n",
    "        response = urllib.request.urlopen(req)\n",
    "        if response.getcode() == 200:\n",
    "            print (\"[%s] Url Request Success\" % datetime.datetime.now())\n",
    "            return response.read().decode('utf-8')\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        print(\"[%s] Error for URL : %s\" % (datetime.datetime.now(), url))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNaverSearchResult(sNode, search_text, page_start, display):\n",
    "    \n",
    "    base = \"https://openapi.naver.com/v1/search\"\n",
    "    node = \"/%s.json\" % sNode\n",
    "    parameters = \"?query=%s&start=%s&display=%s\" % (urllib.parse.quote(search_text), page_start, display)\n",
    "    url = base + node + parameters\n",
    "    \n",
    "    retData = get_request_url(url)\n",
    "    \n",
    "    if (retData == None):\n",
    "        return None\n",
    "    else:\n",
    "        return json.loads(retData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPostData(post, jsonResult):\n",
    "    \n",
    "    title = post['title']\n",
    "    description = post['description']\n",
    "    link = post['link']\n",
    "    \n",
    "    #if 'blog.naver' in link :\n",
    "    #    jsonResult.append({'title':title, 'description': description, 'link': link})\n",
    "        \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def makeJson():\n",
    "\n",
    "    jsonResult = []\n",
    "\n",
    "    # 'news', 'blog', 'cafearticle', 'kin'\n",
    "\n",
    "    sNode = 'blog'\n",
    "    search_text = '일상'\n",
    "    display_count = 100\n",
    "    \n",
    "    jsonSearch = getNaverSearchResult(sNode, search_text, 1, display_count)\n",
    "    \n",
    "    while ((jsonSearch != None) and (jsonSearch['display'] != 0)):\n",
    "        for post in jsonSearch['items']:\n",
    "            getPostData(post, jsonResult)\n",
    "        \n",
    "        nStart = jsonSearch['start'] + jsonSearch['display']\n",
    "        jsonSearch = getNaverSearchResult(sNode, search_text, nStart, display_count)\n",
    "    \n",
    "    with open('%s_naver_%s.json' % (search_text, sNode), 'w', encoding='utf8') as outfile:\n",
    "        retJson = json.dumps(jsonResult,\n",
    "                        indent=4, sort_keys=True,\n",
    "                        ensure_ascii=False)\n",
    "        outfile.write(retJson)\n",
    "        \n",
    "    print ('%s_naver_%s.json SAVED' % (search_text, sNode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeLinkList():\n",
    "    items = json.load(open(\"일상_naver_blog.json\", \"r\", encoding=\"utf-8\"))\n",
    "    links = []\n",
    "    \n",
    "    i = 1\n",
    "    for item in items:\n",
    "        print(str(i) + \" : \" + item[\"link\"])\n",
    "        links.append(item[\"link\"])\n",
    "            \n",
    "        if i == 100:\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "    \n",
    "    return links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def textCrawling(links):\n",
    "    \n",
    "    wfile = open(os.getcwd() + \"/일상_naver_blog.txt\", mode='w', encoding='utf-8')\n",
    "    \n",
    "    idx = 1\n",
    "    for link in links:\n",
    "        driver = webdriver.Chrome(\"/Users/leesoyeon/chromedriver\")\n",
    "        driver.get(link)\n",
    "\n",
    "        driver.switch_to.frame(\"mainFrame\")\n",
    "        html = driver.page_source\n",
    "    \n",
    "        bs = BeautifulSoup(html, 'html.parser')\n",
    "        # print(bs.prettify())\n",
    "\n",
    "        textResult_1 = bs.find_all('div', {'class':['se-text', '__se_component_area']})\n",
    "        textResult_2 = bs.find_all('div', {'id':'postViewArea'})\n",
    "        \n",
    "        print(\"naver_blog_\" + str(idx) + \" \")\n",
    "        \n",
    "        wfile.write(\"naver_blog_\" + str(idx))\n",
    "        \n",
    "        for text in textResult_1:\n",
    "            print(text.get_text())\n",
    "            wfile.write(text.get_text())\n",
    "        \n",
    "        for text in textResult_2:\n",
    "            print(text.get_text())\n",
    "            wfile.write(text.get_text())\n",
    "        \n",
    "        \n",
    "        idx = idx + 1\n",
    "        driver.close()\n",
    "    \n",
    "    wfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2019-11-08 19:28:44.614207] Url Request Success\n",
      "[2019-11-08 19:28:45.228064] Url Request Success\n",
      "[2019-11-08 19:28:45.843413] Url Request Success\n",
      "[2019-11-08 19:28:46.456637] Url Request Success\n",
      "[2019-11-08 19:28:47.070234] Url Request Success\n",
      "[2019-11-08 19:28:47.687928] Url Request Success\n",
      "[2019-11-08 19:28:48.299379] Url Request Success\n",
      "[2019-11-08 19:28:48.914992] Url Request Success\n",
      "[2019-11-08 19:28:49.530840] Url Request Success\n",
      "[2019-11-08 19:28:50.143048] Url Request Success\n",
      "HTTP Error 400: Bad Request\n",
      "[2019-11-08 19:28:50.225314] Error for URL : https://openapi.naver.com/v1/search/blog.json?query=%EC%9D%BC%EC%83%81&start=1001&display=100\n",
      "일상_naver_blog.json SAVED\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    makeJson()\n",
    "    links = makeLinkList()\n",
    "    #links = [\"https://blog.naver.com/charmjouny/221272169614\"]\n",
    "    #result = textCrawling(links)\n",
    "    \n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
